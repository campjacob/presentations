---
layout: single_presentation_all_slides
title: "Week 08 - Program Evaluation Group Designs and Methods"
presentation_id: vPdlBS
canonical_url: /presentations/vPdlBS/
slides:
  - slide_name: ../deck-4951-large-0.jpeg
    slide_text: >
      <p><strong>Location</strong>: CBC Campus -  SWL 208<br />
      <strong>Time</strong>: Mondays from 5:30-8:15<br />
      <strong>Week 08</strong>: 3/2/20<br />
      <strong>Topic and Content Area</strong>: Group Designs and Methods<br />
      <strong>Reading Assignment</strong>: Kapp and Anderson chapter 10<br />
      <strong>Assignments Due</strong>:</p>
      <ul>
      <li>A-02 Reading Quiz 03/02/20</li>
      <li>A-04a: Weekly Journal 04 03/08/20</li>
      </ul>
      <p><strong>Other Important Information</strong>: N/A</p>
      
  - slide_name: ../deck-4951-large-1.jpeg
    slide_text: >
      <ul>
      <li>Checking in for the group work plan</li>
      <li>Key components for evaluation methods</li>
      <li>Threats to validity</li>
      <li>Types of group designs</li>
      </ul>
      
  - slide_name: ../deck-4951-large-2.jpeg
    slide_text: >
      <p>Follow up with how people are doing, see if there is questions around group work plan</p>
      
  - slide_name: ../deck-4951-large-3.jpeg
    slide_text: >
      <p>Later chapters we will be talking about…</p>
      <ul>
      <li>Qualitative designs and applications</li>
      <li>Consumer satisfaction</li>
      </ul>
      <p>Read ahead if these are models you plan on following.</p>
      
  - slide_name: ../deck-4951-large-4.jpeg
    slide_text: >
      <blockquote>
      <p>Any method for evaluation needs to include:</p>
      </blockquote>
      <ul>
      <li>Sample selection</li>
      <li>Data collection</li>
      <li>Analysis</li>
      <li>Reporting</li>
      </ul>
      
  - slide_name: ../deck-4951-large-5.jpeg
    slide_text: >
      <blockquote>
      <p>What kinds of sampling methods.
      [Whole Class Activity] Discussion regarding what types of sampling methods planning on using for groups.</p>
      </blockquote>
      
  - slide_name: ../deck-4951-large-6.jpeg
    slide_text: >
      
  - slide_name: ../deck-4951-large-7.jpeg
    slide_text: >
      <ul>
      <li>
      <strong>History</strong>: Events that happen outside of evaluation or contextually during the evaluation that effect the event. (Corona Virus, people being laid off… etc)</li>
      <li>
      <strong>Maturation and the passage of time</strong>: general growth that happens on it’s own. Especially true for children, but can be true for anybody.</li>
      <li>
      <strong>Testing</strong>: Pre-test effects the outcome of the post-test.</li>
      <li>
      <strong>Instrumentation</strong>: Change in the tools used to collect data during time of data collection (e.g. changing questions on pre-test/post-test)</li>
      <li>
      <strong>Statistical regression</strong>: When there are significant changes (improvement / deterioration) that is based on their extreme behavior or position prior. (Think nowhere to go but up/down)</li>
      </ul>
      
  - slide_name: ../deck-4951-large-8.jpeg
    slide_text: >
      <ul>
      <li>
      <strong>Selection bias</strong>: Problems related to selection of participants (more random and larger sample better)</li>
      <li>
      <strong>Experimental mortality and attrition</strong>: Not completing the intervention or process.</li>
      <li>
      <strong>Ambiguity about the direction of causal influences</strong>: Direction of impacts and influencing conditions not clear. (Depressed causes lack of sleep or lack of sleep causes depression)</li>
      <li>
      <strong>Design contamination</strong>: change behaviors or actions because of being evaluated.</li>
      <li>
      <strong>Diffusion or imitation of treatments</strong>: looking for unique qualities which might be used by other professions (many professionals use strengths-based practice… not only ones that work in a “strengths-based program)</li>
      </ul>
      
  - slide_name: ../deck-4951-large-9.jpeg
    slide_text: >
      <p><strong>Interaction Effects</strong>: Threats to internal validity interact with each other.</p>
      
  - slide_name: ../deck-4951-large-10.jpeg
    slide_text: >
      <ul>
      <li>Defining and describing the intervention or program elements to be evaluated</li>
      <li>Establishing the time order of the independent variable</li>
      <li>Manipulating the independent variable</li>
      <li>Establishing the relationship between the independent and dependent variables</li>
      <li>Controlling for rival hypotheses</li>
      <li>Using at least one control group</li>
      <li>Assigning the person who are subjects in a random manner</li>
      </ul>
      
  - slide_name: ../deck-4951-large-11.jpeg
    slide_text: >
      <p>Work in small groups to discuss potential evaluation or aspect of your group you could test by pre-test / post-test (even if you aren’t going to do this or “wouldn’t be able to” and create a simple example pre/post test</p>
      
  - slide_name: ../deck-4951-large-12.jpeg
    slide_text: >
      <ul>
      <li>Case study approach</li>
      <li>One group post-test design</li>
      <li>One-group pre-test and post-test</li>
      <li>Post-test only with nonequivalent groups</li>
      <li>Experimental design</li>
      <li>Matched comparison groups</li>
      </ul>
      
  - slide_name: ../deck-4951-large-13.jpeg
    slide_text: >
      <ul>
      <li>Are you going to use a group design for your program evaluation or what method will you be using?</li>
      <li>What type of group design method are you going to use?</li>
      <li>What are the challenges that you think you will encounter</li>
      </ul>
      
  - slide_name: ../deck-4951-large-14.jpeg
    slide_text: >
      <p><strong>Description</strong>: The group in which an intervention has been introduced is the focus of the study that will chronicle the progress and process of the gorup describing the changes (or lack of change) after the introduction of the intervention</p>
      <p><strong>Strengths</strong>:</p>
      <ul>
      <li>Detailed exploration</li>
      <li>Ability to understand complexity</li>
      <li>Rich narrative</li>
      </ul>
      <p><strong>Limitations</strong>:</p>
      <ul>
      <li>No comparison group</li>
      <li>Case may not have same qualities as sample</li>
      <li>Difficult to weigh elements of narrative</li>
      </ul>
      
  - slide_name: ../deck-4951-large-15.jpeg
    slide_text: >
      <p><strong>Description</strong>: This design invovles the implementation of an intervention with a group of people whom that intervention wth a group of people for whom that intervention was designed, and then the adminstration of a simple test or other measurement to ascertain the results of that intervention.</p>
      <p>This can be described as an A-B design, with A being the pre-intervention status and B representing the post -intervention status</p>
      <p><strong>Strengths</strong>:</p>
      <ul>
      <li>Design is simple and practical</li>
      <li>Intervention is intended to increase positive outcome</li>
      <li>Intervention delivered and measured</li>
      </ul>
      <p><strong>Limitations</strong>: There are concerns about the validity of the findings, the validity of the measurement instrument, and consequently, the inability to present the effectiveness of the intervention with a high degree of confidence</p>
      
  - slide_name: ../deck-4951-large-16.jpeg
    slide_text: >
      <p><strong>Description</strong>: A target group is assessed prior to the intervention and after the intervention they are assessed again using the same measurement tool. It is designed to measure the change that was presumably caused by the intervention.</p>
      <p><strong>Strengths</strong>:</p>
      <ul>
      <li>Can show comparison between before and after the intervention</li>
      <li>Progress is likely attributable in part to the intervention</li>
      </ul>
      <p><strong>Limitations</strong>:</p>
      <ul>
      <li>Threats to internal validity</li>
      <li>Historical considerations</li>
      <li>Maturation</li>
      <li>Testing and instrumentation</li>
      </ul>
      
  - slide_name: ../deck-4951-large-17.jpeg
    slide_text: >
      <p><strong>Description</strong>: The post-test only aspect of this design means that the impact of the intervention is only delivered after the intervention. The experience annd success of othe clients also served by the agency, who have not recieved the intervention is also measured.</p>
      <p><strong>Strengths</strong>: Simplicity of the post-test only design combined with a simple, accessible method for comparison</p>
      <p><strong>Limitations</strong>: Concerns abut the ability to compare nonequivalent groups and the lac k of randomization mean that strong questions about the validity persist.</p>
      
  - slide_name: ../deck-4951-large-18.jpeg
    slide_text: >
      <p><strong>Description</strong>: The persons to be studied are randomly assigned to two groups. one group is administered the intervention and the other group is not administered the intervention. The condition and status of both groups (e.g. experemental group and control) are measured.</p>
      <p><strong>Strengths</strong>:</p>
      <ul>
      <li>Allows ability to control threats to internal validity</li>
      <li>Presents a higher degree of confidence in the results of the evaluation and effectiveness of the intervention</li>
      </ul>
      <p><strong>Limitations</strong>:</p>
      <ul>
      <li>The cost and effort to create this type of experimental design is higher than others</li>
      <li>Ethical concerns association with withholding treatment</li>
      </ul>
      
  - slide_name: ../deck-4951-large-19.jpeg
    slide_text: >
      <p><strong>Description</strong>: Control group not selected by randomly withholding the intervention</p>
      <p><strong>Strengths</strong>:</p>
      <ul>
      <li>May not present the dilemmas posed by an experimental design</li>
      <li>Is more compatible with ongoing service delivery</li>
      <li>Offers some degree of rigor as it attempts to answer the questions as to the effect of experiencing the benefits of the information</li>
      </ul>
      <p><strong>Limitations</strong>: Potentially challenging to identify comparison groups</p>
      
---
